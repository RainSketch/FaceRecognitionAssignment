{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Data extraction and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameList=['','1.Xiaoming','2.Lihua','3.Lilei','4.Liping','5.Zhangli','6.Zhangsong','7.Pingan','8.Wuhan','9.Liusong','10.Wuyong','11.Donald Trump','12.Joseph Robinette Biden,Jr','13.ntony Blinken','14.Lloyd Austin','15.Hillary Diane Rodham Clinton','16.Niyuwei','17.Zhanghongjun','18.Lionel Messi','19.Cristiano Ronaldo','20.Liyifeng','21.Angelina','22.Anna','23.Macron','24.Rishi','25.Scarlett','26.Zhang Hongjun','27.Wu Jingk','28.Shen Teng','29.Sun Li','30.Deng Chao','31.Chenqiaoen','32.Yangying,mask','33.Sunhonglei','34.Hanxue','35.Jingboran','36.Dilireba','37.Yangmi','38.Zhangxinyu','39.Niyuwei','40.Jane','41.Yan Shirui','42.Yan Zhihou']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt displays grayscale images\n",
    "def plt_show(img):\n",
    "    plt.imshow(img,cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all images in a folder, input parameter is file name, return file address list\n",
    "def read_directory(directory_name):\n",
    "    faces_addr = []\n",
    "    for filename in os.listdir(directory_name):\n",
    "        faces_addr.append(directory_name + \"/\" + filename)\n",
    "    return faces_addr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all face folders and save image addresses in the list\n",
    "faces = []\n",
    "for i in range(1,43):###########\n",
    "    faces_addr = read_directory('./train_f/s'+str(i))\n",
    "    for addr in faces_addr:\n",
    "        faces.append(addr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image data and generate the list label\n",
    "images = []\n",
    "labels = []\n",
    "for index,face in enumerate(faces):\n",
    "    image = cv2.imread(face,0)\n",
    "    images.append(image)\n",
    "    labels.append(int(index/5+1))\n",
    "print(len(labels))\n",
    "print(len(images))\n",
    "print(type(images[0]))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PCA dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the image data into a eigenmatrix\n",
    "image_data = []\n",
    "for image in images:\n",
    "    data = image.flatten()\n",
    "    image_data.append(data)\n",
    "print(image_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a numpy array\n",
    "X = np.array(image_data)\n",
    "y = np.array(labels)\n",
    "print(type(X))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sklearn's pca module\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Draw the eigenmatrix\n",
    "import pandas as pd\n",
    "data = pd.DataFrame(X)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition data set\n",
    "x_train,x_test,y_train,y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training PCA model\n",
    "pca=PCA(n_components=160)\n",
    "pca.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the data set after dimensionality reduction of the test set and training set\n",
    "x_train_pca = pca.transform(x_train)\n",
    "x_test_pca = pca.transform(x_test)\n",
    "print(x_train_pca.shape)\n",
    "print(x_test_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = pca.components_\n",
    "V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature face\n",
    "# Create the canvas and subgraph objects\n",
    "fig, axes = plt.subplots(4,40\n",
    "                       ,figsize=(15,15)\n",
    "                       ,subplot_kw = {\"xticks\":[],\"yticks\":[]} #Do not display axes\n",
    "                       )\n",
    "#Fill image\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(V[i,:].reshape(100,100),cmap=\"gray\") #Select a color pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns how much of the original data the feature carries\n",
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the number of features and the number of messages they carry\n",
    "explained_variance_ratio = []\n",
    "for i in range(1,160): \n",
    "    pca=PCA(n_components=i).fit(x_train)\n",
    "    explained_variance_ratio.append(pca.explained_variance_ratio_.sum())\n",
    "plt.plot(range(1,160),explained_variance_ratio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model creation and training\n",
    "model = cv2.face.EigenFaceRecognizer_create()\n",
    "model.train(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast\n",
    "res = model.predict(x_test[0])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test the accuracy of the data set\n",
    "ress = []\n",
    "true = 0\n",
    "for i in range(len(y_test)):\n",
    "    res = model.predict(x_test[i])\n",
    "#     print(res[0])\n",
    "    if y_test[i] == res[0]:\n",
    "        true = true+1\n",
    "    else:\n",
    "        print(i)\n",
    "\n",
    "print('Test set identification accuracy:%.2f'% (true/len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average face\n",
    "mean = model.getMean()\n",
    "print(mean)\n",
    "meanFace = mean.reshape(100,100)\n",
    "plt_show(meanFace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Custom picture Test (Face recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension reduction\n",
    "pca=PCA(n_components=160)\n",
    "pca.fit(X)\n",
    "X = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all the data as a training set\n",
    "# Model creation and training\n",
    "model = cv2.face.EigenFaceRecognizer_create()\n",
    "model.train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt displays color pictures\n",
    "def plt_show0(img):\n",
    "    b,g,r = cv2.split(img)\n",
    "    img = cv2.merge([r, g, b])\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Face detection\n",
    "def face_detection(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    face_detect = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
    "    face = face_detect.detectMultiScale(gray)\n",
    "    for x,y,w,h in face:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),color=(0,0,255),thickness=2)\n",
    "    cv2.imshow('result (press Esc to terminate)',img)\n",
    "\n",
    "#Read camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.read()\n",
    "while True:\n",
    "    flag,frame = cap.read()\n",
    "    if not flag:\n",
    "        break;\n",
    "    face_detection(frame)\n",
    "    if cv2.waitKey(2)==27:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "##Save a photo\n",
    "def get_photo():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    f, frame = cap.read()\n",
    "    cv2.imwrite('./test_f/image.jpg', frame)\n",
    "    cap.release()\n",
    "get_photo()\n",
    "###\n",
    "face_engine = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
    "img = cv2.imread('./test_f/image.jpg')\n",
    "plt_show0(img)\n",
    "# Copy image grayscale processing\n",
    "img_ = img.copy()\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "# Detect the face to get the face region\n",
    "faces = face_engine.detectMultiScale(gray)\n",
    "# Visualize the detected faces\n",
    "for(x, y, w, h) in faces:\n",
    "    cv2.rectangle(img_, (x, y), (x + w, y + h), (0, 0, 255), 3)\n",
    "    plt_show0(img_)\n",
    "    face = img[y:y + w + 10, x:x + h + 10]\n",
    "    plt_show0(face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImage=\"./test_f/image.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the face cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread(testImage)\n",
    "plt_show0(img)\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect the face in the image\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "# Loop over all the faces in the image\n",
    "for (x, y, w, h) in faces:\n",
    "    # Add a margin around the face\n",
    "    margin = 10\n",
    "    x = x - margin\n",
    "    y = y - margin\n",
    "    w = w + margin*2\n",
    "    h = h + margin*2\n",
    "\n",
    "    # Crop the image to the face\n",
    "    face_img = img[y:y+h, x:x+w]\n",
    "\n",
    "    # Resize the face image to 100x100 pixels\n",
    "    resized_face = cv2.resize(face_img, (100, 100))\n",
    "plt_show0(resized_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(resized_face, cv2.COLOR_BGR2GRAY)\n",
    "plt_show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "imgs.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigenmatrix\n",
    "image_data = []\n",
    "for img in imgs:\n",
    "    data = img.flatten()\n",
    "    image_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array(image_data)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The trained pca model was used to reduce the dimension of the picture\n",
    "test = pca.transform(test)\n",
    "test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Expression recognition\n",
    "from deepface import DeepFace\n",
    "facial=cv2.imread(testImage)\n",
    "result=DeepFace.analyze(img_path=testImage,actions=['emotion'],enforce_detection=False)\n",
    "plt_show0(facial)\n",
    "print(\"Expression:\")\n",
    "print(result)\n",
    "##Face recognition\n",
    "print('Face recognition result：',res[0])\n",
    "print(nameList[res[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
